---
published: false
title: 'Beez, WebRTC + Audio API'
description: 'Here is Beez, a second experiment with the Web Audio API made in one Hackday at Zenexity. This experiment was much more focused on having the best latency performance, and for that purpose we used the bleeding-edge WebRTC technology, which allows to link clients in Peer-to-Peer instead of a classical Client-Server architecture.'
thumbnail: /images/2013/09/beez.png
author: Gaetan
layout: post
tags:
 - WebRTC
 - audio
 - hackday
---

[webaudioapi]: https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html
[zenexity]: http://zenexity.com
[github]: http://github.com/gre/beez
[app]: http://beez.greweb.fr/
[webrtc]: http://www.webrtc.org/
[webrtcapi]: http://www.w3.org/TR/webrtc/
[websocketapi]: http://www.w3.org/TR/websockets/
[fm_article]: /2013/08/FM-audio-api
[playframework]: http://playframework.com/

<img src="/images/2013/09/beez.png" alt="" class="thumbnail-left" />

Here is **Beez**, a second experiment with the [Web Audio API][webaudioapi] 
made in one Hackday at [Zenexity][zenexity].

This experiment was much more focused on having the best **latency performance**,
and for that purpose we used the bleeding-edge [WebRTC][webrtcapi] technology,
which allows to link clients in Peer-to-Peer instead of a classical Client-Server architecture.

* [The project on Github][github]
* [Test it now!][app]


### Live demo of the Hackday application

<iframe width="640" height="480" src="//www.youtube.com/embed/QwU6IMNLF0o" frameborder="0" allowfullscreen></iframe>

*Bonus for the one who recognizes the melody :-)*

<!-- more -->

## The Experiment

The experiment consists of controlling an audio stream running on a desktop web page with 
some audio effect pads running on phones via a mobile web interface.
**Our main goal was to make the best real-time experience.**

### Hive and Bees

An Hive is controlled by different Bees, eventhing connected in Peer-to-Peer (via WebRTC).

#### The Hive

The **Hive** is a web page where the sound is generated and visualized *(Web Audio API)*.
It also shows you in real-time the different effects XY pads and allows you to control them.

![](/images/2013/09/hive.png)

#### A Bee

The **Bee** is a mobile web page which allows you to control the different sound effects with XY pads.
It only works on Android Chrome now *(WebRTC required)*.

![](/images/2013/09/bee.png)

### Audio tech

We have a note sequencer which plays a ***famous melody*** through a [Frequency Modulator][fm_article] and different other effects.

Some controls allows to change the **BPM**, **gain** of the carrier and the modulator, **finetune**, 
frequency **multiplicator** (0.25, 0.5, 1, 1.5, 2) of the carrier and the modulator,
**reverbation**, **filter** (frequency and resonance).

There is also a delay effect made on both left and right channels to produce a cool stereo effect.

## WebSocket VS WebRTC

<img src="/images/2013/09/websocket.png" class="thumbnail-left" />

[WebSocket][websocketapi] is today used in most "real-time" web experiments you see on the Internet.
WebSockets are good, it's a significant evolution from the Ajax years.

WebSocket is a protocol on top of TCP, which **links a browser with a server in a bidirectional text communication**.
Making 2 clients communicating generally consists of broadcasting messages from the server to all clients 
(see the schema).

**This architecture have some advantages:**

* Simple to understand, Easy to use.
* We can easily implement some server validation.

**But also have some drawbacks:**

* Not always easy to traverse **proxies**. *(e.g. through an nginx front server)*
* Only text communication.
* **bandwith** intensive. *(all the bandwidth goes back and forth with your server)*
* **CPU** intensive. *(e.g. receiving 20 messages per second from 10 clients can be a lot for a small server, especially if you are doing some message processing)*

(The two last cons are scalability issues)

<hr style="clear:both" />

<img src="https://upload.wikimedia.org/wikipedia/commons/a/ac/Logo-webrtc.png" class="thumbnail-left" />

[WebRTC][webrtc] (*Web Real Time Communication*), 
is a new web technology which helps to connect browsers in **Peer to Peer**.

WebRTC has been designed for transfering binary data like files, audio, video (e.g. webcam stream).
Of-course, we can still use it for text.

<br style="clear:both" />

<img src="/images/2013/09/webrtc.png" class="thumbnail-right" />

Unlike WebSocket, multiple steps are required to **establish a P2P connection between two web clients**.
It is due to the fact that the two clients must resolve the closest network path to communicate to each other.
That resolving phase need a communication between the clients, and for that we can use WebSocket as a *"Control Channel"*.

Once the two web clients are connected, they basically don't need the web server anymore and can **communicate directly together**.
If the two clients are in the same local network, they should directly communicate through that local network.
That's **reduce the server load** and should significantly **decrease the latency**.

### Playframework / Akka Actors

[Playframework][playframework] has been used on the server side for making that WebSocket Control Channel,
and akka was convenient for handling peers communication and rooms management.

## About the melody

You still didn't guess where does the melody came from?

Well, here is the answer:

<iframe width="640" height="480" src="//www.youtube.com/embed/3rU_ei_x0Ag" frameborder="0" allowfullscreen></iframe>

